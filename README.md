# Speech-Emotion-Recognition
This project develops a speech emotion recognition (SER) system using deep learning techniques. The system is trained on the RAVDESS dataset, consisting of audio recordings of actors expressing different emotions. Mel-Frequency Cepstral Coefficients (MFCCs) are extracted as input features for a Convolutional Neural Network (CNN) model. 
